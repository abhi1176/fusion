{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"signature_data\"\n",
    "maxlen = 200  # Maximum number of strokes\n",
    "labels = os.listdir(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_from_txt(filename):\n",
    "    folder = os.path.basename(os.path.dirname(filename))\n",
    "    data = np.loadtxt(filename, skiprows=1)\n",
    "    # Column-wise min-max scaling\n",
    "    data = (data - data.min(axis=0)) / (data.max(axis=0) - data.min(axis=0))\n",
    "    if len(data) < maxlen:\n",
    "        pad = maxlen - len(data)\n",
    "        data = np.pad(data, ((0, pad), (0, 0)))\n",
    "    data = data[:maxlen, :]\n",
    "    label = to_categorical(labels.index(folder), num_classes=len(labels))\n",
    "    return (data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_data(input_dir, shuffle=False):\n",
    "    files = glob(os.path.join(input_dir, \"*\", \"*\"))\n",
    "    random.shuffle(files)\n",
    "    n = len(files)\n",
    "    def fetch():\n",
    "        i = 0\n",
    "        while True:\n",
    "            if shuffle:\n",
    "                file = random.choice(files)\n",
    "            else:\n",
    "                file = files[i]\n",
    "                i = (i+1)%n\n",
    "            yield features_from_txt(file)\n",
    "    return fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 200, 7) (32, 20)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_generator(generate_data(input_dir), output_types=(tf.float64, tf.uint8), output_shapes=((200, 7), (20,)))\n",
    "dataset = dataset.batch(batch_size)\n",
    "for d in dataset.take(1):\n",
    "    print(d[0].shape, d[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signature_model():\n",
    "    x1 = Input(shape=(maxlen, 7), name='signature_input')\n",
    "    x = LSTM(128, return_sequences=True)(x1)\n",
    "    x = LSTM(64)(x)\n",
    "    x = Dense(20, activation='softmax',name='signature_output')(x)\n",
    "    return Model(inputs=x1, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 20 steps\n",
      "Epoch 1/20\n",
      "20/20 [==============================] - 13s 627ms/step - loss: 2.7516 - accuracy: 0.1562\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 3s 147ms/step - loss: 2.2411 - accuracy: 0.3031\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 3s 146ms/step - loss: 1.7803 - accuracy: 0.4109\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 3s 148ms/step - loss: 1.3661 - accuracy: 0.5547\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 3s 175ms/step - loss: 1.3657 - accuracy: 0.5141\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 3s 146ms/step - loss: 1.0448 - accuracy: 0.6469\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 3s 153ms/step - loss: 0.8682 - accuracy: 0.7063\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 3s 151ms/step - loss: 0.8449 - accuracy: 0.6859\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 3s 162ms/step - loss: 0.7803 - accuracy: 0.7063\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 3s 162ms/step - loss: 0.7324 - accuracy: 0.7250\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 3s 160ms/step - loss: 0.6035 - accuracy: 0.7859\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 4s 201ms/step - loss: 0.4785 - accuracy: 0.8375\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 3s 166ms/step - loss: 0.4642 - accuracy: 0.8250\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 4s 181ms/step - loss: 0.5358 - accuracy: 0.8016\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 3s 153ms/step - loss: 0.5994 - accuracy: 0.7859\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 3s 162ms/step - loss: 0.6927 - accuracy: 0.73912s -\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 3s 150ms/step - loss: 0.5333 - accuracy: 0.7781\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 3s 153ms/step - loss: 0.3732 - accuracy: 0.8531\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 3s 154ms/step - loss: 0.2925 - accuracy: 0.9031\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 3s 174ms/step - loss: 0.2669 - accuracy: 0.9375\n",
      "WARNING:tensorflow:From C:\\Users\\ABHI\\anaconda3\\envs\\ai\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: signature_epochs20_lr0.001_batch32\\assets\n"
     ]
    }
   ],
   "source": [
    "model = signature_model()\n",
    "\n",
    "epochs = 20\n",
    "lr = 0.001\n",
    "save_model_as = \"signature_epochs{}_lr{}_batch{}\"\n",
    "optimizer = Adam(lr=lr)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(dataset, epochs=epochs, steps_per_epoch=20)\n",
    "model.save(save_model_as.format(epochs, lr, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
